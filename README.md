# Καλωσήρθατε στο demo μηχανικής όρασης για ανίχνευση αντικειμένων!

Έχουμε φροντίσει ώστε ότι είναι να τρέξει είναι έτοιμο σε bash script στην ρίζα του φακέλου cv-demo για διευκόλυνση.

Υπάρχουν λοιπόν 6 bash scripts, τα run_darknet.sh,  run_yolomark.sh, run_label_conversion_pt1.sh, run_label_conversion_pt2.sh και run_BEV.sh και weights.sh, τα οποία εξηγούνται παρακάτω.  
Κατεβάστε τον φάκελο στον υπολογιστή σας και δώστε δικαιώματα εκτέλεσης στα bash scripts ώστε να μπορούν να τρέξουν:


```
git clone https://github.com/PericlesPet/cv-demo.git
cd cv-demo/
chmod +x scripts/*.sh
```

Πρώτα, κατεβάστε τα βάρη [εδώ](https://we.tl/t-ovKahZfelq) (33MB), επειδή το github δεν επιτρέπει αρχεία άνω των 25MB. 
Τα βάρη βάλ'τε τα στον φάκελο cv-demo και θα τοποθετηθούν στην σωστή θέση με το bash script weights.sh

```
scripts/weights.sh
```

## Darknet
Στον φάκελο “darknet“ υπάρχει ένα fork του darknet με το δικό μας σετ εκπαίδευσης και μερικές εικόνες για επαλήθευση. Υπάρχουν επίσης όλα τα προσαρμοσμένα αρχεία .cfg, καθώς και κάποια ακόμα αρχεία που έπρεπε να αλλάξουμε για να κάνουμε εκπαίδευση στα δικά μας δεδομένα. 
Λόγω του περιορισμού μεγέθους του github όμως, στο demo/darknet υπάρχει μόνο η αρχιτεκτονική YOLOv3 Tiny ενδεικτικά, αφού τα βάρη των άλλων 2 μοντέλων είναι περίπου 250MB το καθένα. Επίσης υπάρχουν μόνο λίγες από τις εικόνες για επαλήθευση, καθώς το αρχικό σετ για επαλήθευση είναι περίπου 1GB και το σετ εκπαίδευσης είναι 15GB.

Παρόλαυτα, τα βάρη του YOLOv3 Tiny είναι εκπαιδευμένα στο κανονικό, ολόκληρο σετ εκπαίδευσης, οπότε τα αποτελέσματα που θα δείτε στο σετ επαλήθευσης είναι αντιπροσωπευτικά.

Παράλληλα, υπάρχει και ένα .pdf έγγραφο που γράψαμε ως κομμάτι εγχειριδίου χρήσης του darknet που αναφέρει τα διάφορα προγράμματα και βιβλιοθήκες που χρειάζονται για να τρέξει το νευρωνικό, καθώς επίσης και μερικές ακόμα λεπτομέρειες.

Αν τρέξετε το script run_darknet.sh τότε θα γίνει το compilation του darknet και θα ξεκινήσει η ενδεικτική εκπαίδευση:
```
scripts/run_darknet.sh
```

Αφού γίνει το compilation, μπορείτε να κάνετε "pseudo-labeling" του σετ επαλήθευσης, δημιουργώντας ως "annotations" τα αποτελέσματα του "inference" του δικτύου στις εικόνες που χρησιμοποιούνται για επαλήθευση, και να δείτε οπτικά το αποτέλεσμα με το εργαλείο Yolo_Mark. Για διευκόλυνση έχουμε ήδη κατεβασμένο το Yolo_Mark σε αυτόν τον φάκελο.
Τρέξτε: 
```
scripts/run_yolomark.sh
```

**Σημείωση:** Για να κλείσει το Yolo_mark πρέπει να δώσετε Termination Signal από το τερματικό. Στο τερματικό από το οποίο τρέξατε το run_yolomark.sh, πατήστε **Ctrl+C** 


## Birds Eye View (BEV)
Στον φάκελο BEV υπάρχει επίσης ένα παράδειγμα σε python του μετασχηματισμού Bird’s Eye View. 
Χρειάζεται εγκατάσταση του OpenCV για Python, αλλά θεωρητικά αν κάνατε τις απαραίτητες εγκαταστάσεις για το YOLOv3 είστε καλυμμένοι. 

```
scripts/run_bev.sh 
```

## Label Conversion
Στον φάκελο label conversion έχουμε ένα παράδειγμα από την μετατροπή των “label” των σετ δεδομένων των άλλων ομαδών στα δικά μας μέτρα. Στην πραγματικότητα χρησιμοποιήθηκαν πολλά script για conversion από διάφορα format, όπως VOC, XML based, MIT LabelMe Webtool format , και διάφορα άλλα. 

Στην προκειμένη περίπτωση το παράδειγμα είναι απλά για την αλλαγή των δεικτών των κλάσεων σε ενα ολόκληρο “dataset” όταν είναι και αυτό σε Yolo Darknet Format, αλλά με διαφορετική δεικτοδότηση. 

Υπάρχουν 2 shell scripts για εδώ, ώστε να φανεί η διαφορά πριν και μετά.

```
scripts/run_label_conversion_pt1.sh 
```

Τώρα φαίνεται πως θα τις "έβλεπε" τις εικόνες το νευρωνικό αν χρησιμοποιούσαμε το dataset αυτούσιο. Το κεντρικό νόημα είναι ότι έχει αλλάξει η "σειρά" των κλάσεων, οπότε όλα είναι λάθος.
Αφού τελειώσετε, πατήστε **Ctrl+C** από το τερματικό ώστε να κλείσει το Yolo_mark.

Για να κάνετε την μετατροπή των label, τρέξτε:

```
scripts/run_label_conversion_pt2.sh 
```
Αφού τελειώσετε, πατήστε πάλι **Ctrl+C** από το τερματικό.

